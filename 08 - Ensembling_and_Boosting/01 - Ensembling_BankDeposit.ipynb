{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../CSV/bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   59    0        1          1        0     2343        1     0        2   \n",
       "1   56    0        1          1        0       45        0     0        2   \n",
       "2   41    9        1          1        0     1270        1     0        2   \n",
       "3   55    7        1          1        0     2476        1     0        2   \n",
       "4   54    0        1          2        0      184        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  deposit  \n",
       "0    5      8      1042         1     -1         0         3        1  \n",
       "1    5      8      1467         1     -1         0         3        1  \n",
       "2    5      8      1389         1     -1         0         3        1  \n",
       "3    5      8       579         1     -1         0         3        1  \n",
       "4    5      8       673         2     -1         0         3        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "df[\"deposit\"].value_counts().plot.pie(autopct=\"%1.1f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "dt1 = DecisionTreeClassifier()\n",
    "dt2 = DecisionTreeClassifier(criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [('lr',lr),('dt1',dt1),('dt2',dt2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1. Hard voting</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc1 =  VotingClassifier(estimators=model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83      1760\n",
      "           1       0.81      0.82      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('dt1',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None...\n",
       "                             ('dt2',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='entropy',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort=False,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(vc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2. Soft voting</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc2 = VotingClassifier(estimators=model_list,voting=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1760\n",
      "           1       0.81      0.82      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('dt1',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None...\n",
       "                             ('dt2',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='entropy',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort=False,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(vc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1. Bagging</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use odd no. of n_estimators for hard voting for better result\n",
    "bg1 = BaggingClassifier(LogisticRegression(),n_estimators=9,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1760\n",
      "           1       0.79      0.78      0.78      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                    dual=False,\n",
       "                                                    fit_intercept=True,\n",
       "                                                    intercept_scaling=1,\n",
       "                                                    l1_ratio=None, max_iter=100,\n",
       "                                                    multi_class='warn',\n",
       "                                                    n_jobs=None, penalty='l2',\n",
       "                                                    random_state=None,\n",
       "                                                    solver='warn', tol=0.0001,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=9, n_jobs=None, oob_score=False,\n",
       "                  random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(bg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2. Pasting<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasting - bootstrap=Flase\n",
    "bg2 = BaggingClassifier(LogisticRegression(),n_estimators=9,random_state=1,bootstrap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1760\n",
      "           1       0.79      0.78      0.78      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                    dual=False,\n",
       "                                                    fit_intercept=True,\n",
       "                                                    intercept_scaling=1,\n",
       "                                                    l1_ratio=None, max_iter=100,\n",
       "                                                    multi_class='warn',\n",
       "                                                    n_jobs=None, penalty='l2',\n",
       "                                                    random_state=None,\n",
       "                                                    solver='warn', tol=0.0001,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                  bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=9, n_jobs=None, oob_score=False,\n",
       "                  random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(bg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap output is not better than Naive aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bg3 = BaggingClassifier(DecisionTreeClassifier(),n_estimators=10,max_samples=100,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      1760\n",
      "           1       0.80      0.85      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=11,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning using maxfeature\n",
    "rf2 = RandomForestClassifier(n_estimators=11,max_features=11,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=11, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=11,\n",
       "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(rf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this command in anaconda prompt \n",
    "# conda install mlxtend --channel conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "dt1 = DecisionTreeClassifier()\n",
    "dt2 = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "model_list = [lr,dt1,dt2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta classifier model --> Logistic Reg / Decision Tree\n",
    "meta_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack =  StackingClassifier(classifiers=model_list,meta_classifier=meta_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80      1760\n",
      "           1       0.75      0.89      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.80      3349\n",
      "weighted avg       0.82      0.81      0.80      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                   dual=False,\n",
       "                                                   fit_intercept=True,\n",
       "                                                   intercept_scaling=1,\n",
       "                                                   l1_ratio=None, max_iter=100,\n",
       "                                                   multi_class='warn',\n",
       "                                                   n_jobs=None, penalty='l2',\n",
       "                                                   random_state=None,\n",
       "                                                   solver='warn', tol=0.0001,\n",
       "                                                   verbose=0,\n",
       "                                                   warm_start=False),\n",
       "                                DecisionTreeClassifier(class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_...\n",
       "                   meta_classifier=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=100,\n",
       "                                                      multi_class='warn',\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      random_state=None,\n",
       "                                                      solver='warn', tol=0.0001,\n",
       "                                                      verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58201572, 5.9887401 , 5.9887401 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.meta_clf_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack1 =  StackingClassifier(classifiers=model_list,meta_classifier=meta_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1760\n",
      "           1       0.79      0.76      0.77      1589\n",
      "\n",
      "    accuracy                           0.79      3349\n",
      "   macro avg       0.79      0.79      0.79      3349\n",
      "weighted avg       0.79      0.79      0.79      3349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                   dual=False,\n",
       "                                                   fit_intercept=True,\n",
       "                                                   intercept_scaling=1,\n",
       "                                                   l1_ratio=None, max_iter=100,\n",
       "                                                   multi_class='warn',\n",
       "                                                   n_jobs=None, penalty='l2',\n",
       "                                                   random_state=None,\n",
       "                                                   solver='warn', tol=0.0001,\n",
       "                                                   verbose=0,\n",
       "                                                   warm_start=False),\n",
       "                                DecisionTreeClassifier(class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_...\n",
       "                   meta_classifier=DecisionTreeClassifier(class_weight=None,\n",
       "                                                          criterion='gini',\n",
       "                                                          max_depth=None,\n",
       "                                                          max_features=None,\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          presort=False,\n",
       "                                                          random_state=None,\n",
       "                                                          splitter='best'),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(stack1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack1.meta_clf_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
